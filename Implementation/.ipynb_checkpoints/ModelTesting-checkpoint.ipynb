{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c88dc54-4e7a-42ef-a460-6a8657f3516b",
   "metadata": {},
   "source": [
    "<h1>Implementation</h1>\n",
    "This notebook is used to randomly select 10 data sequences of 10 laps and generate blog posts based on those."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3a6b8e-7780-4580-8fe8-7557608d31ee",
   "metadata": {},
   "source": [
    "_Below code can be uncommented to select a GPU that is not yet occupied._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a881bfb2-a81f-40c7-b926-57d46682833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13d7f9f-7edc-47ac-86cf-852b035db467",
   "metadata": {},
   "source": [
    "<h2>Loading the finetuned model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d58dbd02-2b62-404e-88f7-bf6f7cc9f52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model_folder = '../FineTuning/FinetunedModels/RUCAIBox_mvp-data-to-text'\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_folder)\n",
    "tok = AutoTokenizer.from_pretrained(model_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ad5a6f-f58a-4c0b-8347-08d53a1e979e",
   "metadata": {},
   "source": [
    "<h2>Loading and reformatting the race data</h2>\n",
    "In the reformat function, the JSON data is converted to the same format as the format of the data that the LLM was pretrained and finetuned on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a87cff2f-b2b4-462b-9c46-07d759f7be88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "def reformatData(arr):\n",
    "    prompt = 'Write an entertaining live blog post describing the following event in a Formula 1 race: '\n",
    "    for obj in arr:\n",
    "        i = str(arr.index(obj) + 1)\n",
    "        sub, act, obj = obj['subject'], obj['action'], obj['object']\n",
    "        sub_i, act_i, obj_i = 'Agent' + i, 'Action' + i, 'Object' + i\n",
    "        try: sub_cat, sub_ent = [list(s.items()) for s in sub][0][0]\n",
    "        except IndexError: continue\n",
    "        prompt += sub_i + ' | ' + sub_cat + ' | ' + sub_ent + ' [SEP] '\n",
    "        prompt += act_i + ' | ' + act + ' [SEP] '\n",
    "        for key in obj:\n",
    "            obj_cat, obj_lst = key, obj[key]\n",
    "            for obj_ent in obj_lst:\n",
    "                prompt += obj_i + ' | ' + obj_cat + ' | ' + obj_ent + ' [SEP] '\n",
    "    return prompt[:-7]\n",
    "\n",
    "\n",
    "def loadInputData():\n",
    "    input_folder = '../EventIdentification/ExampleEvents4/'\n",
    "    race_folders = [input_folder + f for f in\n",
    "                    os.listdir(input_folder) if 'ipynb' not in f]\n",
    "    prompts, json_data = {}, {}\n",
    "    for rf in race_folders:\n",
    "        rkey = rf.split('/')[-1]\n",
    "        prompts[rkey], json_data[rkey] = {}, {}\n",
    "        lap_files = [f for f in os.listdir(rf) if 'ipynb' not in f]\n",
    "        for lf in lap_files:\n",
    "            lkey = lf.split('.')[0]\n",
    "            fn = rf + '/' + lf\n",
    "            with open(fn, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                if not data: continue\n",
    "                prompts[rkey][lkey] = []\n",
    "                json_data[rkey][lkey] = []\n",
    "                for d in data:\n",
    "                    prompts[rkey][lkey].append(reformatData(d))\n",
    "                    json_data[rkey][lkey].append(d)\n",
    "                # prompts[rkey][lkey] = reformatData(data)\n",
    "    return prompts, json_data\n",
    "\n",
    "\n",
    "prompts, data = loadInputData()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc29dcd-a04c-4b11-a04e-65ae6e2dfd6e",
   "metadata": {},
   "source": [
    "<h2>Selecting the random races</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4beda371-1747-40e5-91ab-e55a9ab96b21",
   "metadata": {},
   "source": [
    "In each year between 2018 and 2023, except for 2020 (as this was a Covid year with many cancelled races), two races are randomly selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1db78e40-213f-4a3b-af39-9d357f493fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def getRandomRacesInYear(keys, year):\n",
    "    keys_fy = [k for k in keys if k.startswith(str(year))]\n",
    "    r1 = random.choice(keys_fy)\n",
    "    r2 = random.choice(keys_fy)\n",
    "    # repeat process if the two races are the same\n",
    "    if r1 == r2: getRandomRacesInYear(keys, year)\n",
    "    else: return [r1, r2]\n",
    "\n",
    "\n",
    "# years, sel_races = [2018, 2019, 2021, 2022, 2023], []\n",
    "years, sel_races = [2023], []\n",
    "for y in years: sel_races += getRandomRacesInYear(list(data.keys()), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89c6d6e-4cc4-43a5-a27a-7c35f836efed",
   "metadata": {},
   "source": [
    "<h2>Generating the blog posts</h2>\n",
    "The post generation function takes care of randomly selecting a sequence of 10 laps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0223911-4673-48c4-aed7-9ee27dac8894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatePosts(prompts):\n",
    "    # nr_laps = len(list(prompts_fr.keys()))\n",
    "    # lap_seq = random.randint(1, nr_laps - 11)\n",
    "    # start, end = lap_seq, lap_seq + 10\n",
    "    # print(start, end)\n",
    "    # keys = list(prompts_fr.keys())[start:end]\n",
    "    # prompts = list(prompts_fr.items())[start:end]\n",
    "    # prompts = prompts_fr[start:end]\n",
    "    model_inputs = tok(prompts, return_tensors='pt', padding=True)\n",
    "    model_output = model.generate(**model_inputs, max_new_tokens=500)\n",
    "    blog_posts = tok.batch_decode(model_output, skip_special_tokens=True)\n",
    "    # return {keys[i]: blog_posts[i] for i in range(len(keys))}\n",
    "    return blog_posts\n",
    "\n",
    "\n",
    "def randomizeSeq(prompts, nr_laps):\n",
    "    lap_seq = random.randint(1, nr_laps - 11)\n",
    "    start, end = lap_seq, lap_seq + 10\n",
    "    return dict(list(prompts.items())[start:end])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933292f1-703e-4e64-8f53-6c9f31363278",
   "metadata": {},
   "source": [
    "<h2>Save CSV files</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "046c1a05-aa9d-4084-b3ed-d99b26f04b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023_jeddah\n",
      "2023_miami\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for r in sel_races:\n",
    "    print(r)\n",
    "    posts, nr_laps = {}, len(list(prompts[r].keys()))\n",
    "    prompt_seq = randomizeSeq(prompts[r], nr_laps)\n",
    "    for lap in prompt_seq:\n",
    "        posts[lap] = generatePosts(prompt_seq[lap])\n",
    "    cols = [['Lap'], ['Data'], ['Prompt'], ['Output']]\n",
    "    for lap in posts:\n",
    "        for i in range(len(posts[lap])):\n",
    "            a = [[lap], [str(data[r][lap][i])], [str(prompts[r][lap][i])], [str(posts[lap][i])]]\n",
    "            for i in range(len(cols)): cols[i] += a[i]\n",
    "    fn = './GeneratedPosts/' + r + '.csv'\n",
    "    np.savetxt(fn, [p for p in zip(*cols)], delimiter=';', fmt='%s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (fituenv)",
   "language": "python",
   "name": "fituenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
